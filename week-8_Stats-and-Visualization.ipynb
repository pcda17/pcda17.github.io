{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the packages we will use below.\n",
    "\n",
    "import os\n",
    "import textblob\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download zipped texts from GitHub, then unzip the directories.\n",
    "\n",
    "os.chdir('/sharedfolder/')\n",
    "\n",
    "!wget -N https://github.com/pcda17/pcda17.github.io/blob/master/week/5/Emerson.zip?raw=true -O Emerson.zip\n",
    "!unzip -o Emerson.zip\n",
    "\n",
    "!wget -N https://github.com/pcda17/pcda17.github.io/blob/master/week/5/Wilde.zip?raw=true -O Wilde.zip\n",
    "!unzip -o Wilde.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, load each author‚Äôs works as a list of strings.\n",
    "\n",
    "corpus_1_dir = \"/sharedfolder/Emerson/\"\n",
    "corpus_2_dir = \"/sharedfolder/Wilde/\"\n",
    "\n",
    "##\n",
    "\n",
    "os.chdir(corpus_1_dir)\n",
    "\n",
    "corpus_1_filenames = os.listdir(\"./\")\n",
    "\n",
    "corpus_1_texts=[]\n",
    "\n",
    "for filename in corpus_1_filenames:\n",
    "    text = open(filename).read().replace(\"\\n\",\" \") #replaces newline characters with spaces\n",
    "    corpus_1_texts.append(text)\n",
    "\n",
    "##\n",
    "    \n",
    "os.chdir(corpus_2_dir)\n",
    "\n",
    "corpus_2_filenames = os.listdir(\"./\")\n",
    "\n",
    "corpus_2_texts=[]\n",
    "\n",
    "for filename in corpus_2_filenames:\n",
    "    text = open(filename).read().replace(\"\\n\",\" \") #replaces newline characters with spaces\n",
    "    corpus_2_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Hello Jupyter!\"\n",
    "print \"Hello\"+\" Jupyter!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer Arithmetic\n",
    "\n",
    "int1=10000\n",
    "int2=150\n",
    "\n",
    "print int1+int2 # add\n",
    "print int1-int2 # subtract\n",
    "print int1*int2 # multiply\n",
    "print int1/int2 # divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floating Point Arithmetic\n",
    "\n",
    "float1=10000.0\n",
    "float2=150.5\n",
    "\n",
    "print float1+float2 # add\n",
    "print float1-float2 # subtract\n",
    "print float1*float2 # multiply\n",
    "print float1/float2 # divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Manipulation\n",
    "## In which we split and reassemble a sentence.\n",
    "\n",
    "sentence=\"A green hunting cap squeezed the top of a fleshy balloon of a head.\"\n",
    "print sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=sentence.split(\" \")\n",
    "print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejoined=\" \".join(words)\n",
    "print rejoined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Slice Notation\n",
    "\n",
    "print len(words)\n",
    "\n",
    "print words[4]\n",
    "print words[2:5]\n",
    "print words[2:]\n",
    "print words[:2]\n",
    "print words[-4]\n",
    "print words[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ñ∑ Lines beginning with **`'!'`** are executed in Bash, i.e., the default Unix environment you're in when you open a new Terminal window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following Bash command displays your username.\n",
    "\n",
    "!whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# And this one prints a list of files on your desktop.\n",
    "\n",
    "!ls /Users/yourname/Desktop/   ### Swap in your username here. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following simplified format does the same.\n",
    "\n",
    "# Note that this shortcut works in Bash but not in Python's 'os' module.\n",
    "\n",
    "!ls ~/Desktop/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ñ∑  Python can execute Bash commands as well, via the `os` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports the 'os' module, then prints a list of filenames on the desktop.\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(\"/Users/yourname/Desktop/\") ### Swap in your username here. ###\n",
    "filenames = os.listdir(\"/Users/yourname/Desktop/\")  ### Swap in your username here. ###\n",
    "print filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pprint module shows us the list above in a more readable format.\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your desktop is filled with screen capture files, uncomment and run the lines below \n",
    "# to create a 'Screenshots' directory and send future captures there by default.\n",
    "\n",
    "# !mkdir ~/Desktop/Screenshots\n",
    "# !defaults write com.apple.screencapture location ~/Desktop/Screenshots ; killall SystemUIServer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Text I/0\n",
    "#### ‚ñ∑ In the following demonstrations we'll be loading plain text files from the Web like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "url=\"http://principalhand.org/workshop-data/Melville_Moby-Dick.txt\"\n",
    "\n",
    "melville_string=urllib2.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ñ∑ And here's how to work with text files on your local system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, this Bash command creates a two-line text file on your desktop.\n",
    "\n",
    "!echo \"This is the first line.\\nThis is the second line.\" > ~/Desktop/test_file.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shortest format for creating a string from a text file:\n",
    "\n",
    "text=open(\"/Users/yourname/Desktop/test_file.txt\").read()  ### Swap in your username here. ###\n",
    "\n",
    "print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we can work with one line at a time. Note that the newline character at the end of the\n",
    "# first line ends up creating a gap when the lines are printed separately.\n",
    "\n",
    "with open(\"/Users/yourname/Desktop/test_file.txt\") as fi:  ### Swap in your username here. ###\n",
    "    for line in fi:\n",
    "        print line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a text file as a list of lines, discarding newline characters.\n",
    "\n",
    "line_list=open(\"/Users/yourname/Desktop/test_file.txt\").read().splitlines()  ### Swap in your username here. ###\n",
    "\n",
    "print line_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And we can write string data to a new text file like so:\n",
    "\n",
    "fo=open(\"/Users/yourname/Desktop/test_file_2.txt\",\"w\")  ### Swap in your username here. ###\n",
    "\n",
    "fo.write(\"This is another first line.\\n\")\n",
    "fo.write(\"This is another second line.\")\n",
    "\n",
    "fo.close()\n",
    "\n",
    "# A file called \"test_file_2.txt\" should appear on your desktop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlined Text Processing with TextBlob\n",
    "\n",
    "Run the following to install TextBlob and download a set of sample corpora for the current user. To install the module for all users, delete the `--user` option and run the commands in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U --user textblob\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's relaunch Python so we can access our newly installed modules.\n",
    "\n",
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ñ∑ Creating a TextBlob object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from pprint import pprint\n",
    "\n",
    "paragraph='''\"There, there, I shall find some employment, although it will not necessarily be what you would call a good job. I may have some valuable insights which may benefit my employer. Perhaps the experience can give my writing a new dimension. Being actively engaged in the system which I criticize will be an interesting irony in itself.\" Ignatius belched loudly. \"If only Myrna Minkoff could see how low I've fallen.\"'''\n",
    "\n",
    "blob_1 = TextBlob(paragraph)\n",
    "\n",
    "print blob_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'blob.words' is a list of words.\n",
    "\n",
    "print blob_1.words[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'blob.sentences' is a list of Sentence objects.\n",
    "\n",
    "pprint(blob_1.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ñ∑ POS tagging\n",
    "\n",
    "You can find a list of POS tags here: http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'blob_1.tags' is a list of NLTK's best guess for each word's part of speech (POS).\n",
    "# The following prints the first 20 word-tag pairs in our text.\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(blob_1.tags[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print blob_1.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse a sentence's grammar in tree form.\n",
    "\n",
    "blob_1.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ‚ñ∑ Now let's work with a longer text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Melville's _Moby Dick_\n",
    "\n",
    "import urllib2\n",
    "\n",
    "url=\"http://principalhand.org/workshop-data/Melville_Moby-Dick.txt\"\n",
    "\n",
    "melville_string=urllib2.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TextBlob object and print a random sentence.\n",
    "\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "\n",
    "melville_blob = TextBlob(melville_string)\n",
    "print random.sample(melville_blob.sentences,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the number of times a given word appears in a text.\n",
    "\n",
    "print melville_blob.words.count('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the most frequently occurring words in a text. Note that this is approach is \n",
    "# case-sensitive.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "print Counter(melville_blob.words).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here's a non-case-sensitive version of the command above, which works by converting the\n",
    "# full text to lowercase before calculating string frequencies.\n",
    "\n",
    "print Counter(melville_blob.words.lower()).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stop Words\n",
    "\n",
    "Now let's view the most frequent words in our corpus with stopwords removed.\n",
    "\n",
    "The first time you run the cell below, uncomment the second line to download all nltk corpora and packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#!python -m nltk.downloader all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading stop word list\n",
    "\n",
    "from operator import itemgetter\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "stopwords_eng=stopwords.words('english')+[\"'s\"] ## Adding \"'s\"  as a stop word\n",
    "print sorted(stopwords_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new Moby Dick TextBlob object (just for convenience)\n",
    "\n",
    "import urllib2\n",
    "url=\"http://principalhand.org/workshop-data/Melville_Moby-Dick.txt\"\n",
    "melville_string=urllib2.urlopen(url).read()\n",
    "\n",
    "\n",
    "# Create a TextBlob object and print a random sentence.\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "\n",
    "melville_blob = TextBlob(melville_string)\n",
    "print random.sample(melville_blob.sentences,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a copy of our word tally list with stopwords removed.\n",
    "from collections import Counter\n",
    "from textblob import Word\n",
    "from pprint import pprint\n",
    "\n",
    "most_freq=Counter(melville_blob.words.lower()).most_common()\n",
    "\n",
    "most_freq_ns=[]\n",
    "\n",
    "for pair in most_freq:\n",
    "    word=pair[0].lower()\n",
    "    pre_apostrophe=Word(word).split(\"'\"[0]) # \n",
    "    if not (word in stopwords_eng)|(pre_apostrophe in stopwords_eng):\n",
    "        most_freq_ns.append(pair)\n",
    "\n",
    "        \n",
    "print len(most_freq_ns)\n",
    "pprint(most_freq_ns[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that applies the process above to any TextBlob object.\n",
    "\n",
    "def most_freq_no_stop(blob):\n",
    "    stopwords_eng=stopwords.words('english')+[\"'s\"]\n",
    "    most_freq=Counter(blob.words.lower()).most_common()\n",
    "    \n",
    "    most_freq_no_stop=[]\n",
    "\n",
    "    for pair in most_freq:\n",
    "        word=pair[0].lower()\n",
    "        pre_apostrophe=Word(word).split(\"'\"[0])\n",
    "        if not (word in stopwords_eng)|(pre_apostrophe in stopwords_eng):\n",
    "            most_freq_no_stop.append(pair)\n",
    "    \n",
    "    return most_freq_no_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(most_freq_no_stop(melville_blob)[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ñ∑ Let's load another text for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "url=\"http://principalhand.org/workshop-data/Austen_Persuasion.txt\"\n",
    "\n",
    "austen_string=urllib2.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This cell will throw an error. Don't panic! ####\n",
    "\n",
    "austen_blob = TextBlob(austen_string)\n",
    "pprint(most_freq_no_stop(austen_blob)[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ñ∑ The cell above will produce a 'UnicodeDecodeError.' To fix the problem, we can apply the \"decode()\" function to our string before passing it to the TextBlob constructor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://principalhand.org/workshop-data/Austen_Persuasion.txt\"\n",
    "\n",
    "austen_string=urllib2.urlopen(url).read().decode(\"utf8\")\n",
    "\n",
    "austen_blob = TextBlob(austen_string)\n",
    "\n",
    "pprint(most_freq_no_stop(austen_blob)[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ñ∑ Yet another word frequency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "url=\"http://principalhand.org/workshop-data/Gilman_Yellow-Wallpaper.txt\"\n",
    "\n",
    "gilman_string=urllib2.urlopen(url).read().decode(\"utf8\")\n",
    "\n",
    "gilman_blob = TextBlob(gilman_string)\n",
    "\n",
    "pprint(most_freq_no_stop(gilman_blob)[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ñ∑ Sanitizing Input\n",
    "\n",
    "Variations in text encoding formats constantly cause trouble, so we'll define a function to clean up a given string.\n",
    "\n",
    "First we'll install the unidecode module, which converts non-ASCII characters like curly quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user -U unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's relaunch Python so we can access our newly installed module.\n",
    "\n",
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "import bleach\n",
    "\n",
    "def sanitize(text):\n",
    "    x=unidecode(bleach.clean(text)) ## Applying two tools together to create proper ASCII text.\n",
    "    x=x.replace(\"\\n\",\" \").replace(\"\\r\",\" \").strip() ## Replacing line breaks spaces and stripping leading and trailing whitespace\n",
    "    while \"  \" in x:\n",
    "        x=x.replace(\"  \",\" \")      ## Replacing all sequences of spaces with a single space\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make sure our sanitizing function works.\n",
    "\n",
    "print sanitize(u\"Gz\\n    7üìé2‚ÄúN\\u0303o‚ÄùI   J√âXüêõvp\")\n",
    "print sanitize(\"5KzMs  BCzsbR   uHJINE8\")\n",
    "\n",
    "# If this shows an error on the first try, run it again and see if it behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ‚ñ∑ Creating a concordance with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import urllib2\n",
    "\n",
    "url=\"http://principalhand.org/workshop-data/Stein_Three-Lives.txt\"\n",
    "temp_string=urllib2.urlopen(url).read().decode('utf8')\n",
    "\n",
    "raw=sanitize(temp_string)\n",
    "\n",
    "\n",
    "nltk_text = nltk.Text([sanitize(temp_string)])\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "nltk_text = nltk.Text(tokens)\n",
    "\n",
    "\n",
    "print nltk_text.concordance('blood')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ñ∑ Simple sentiment analysis with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative polarity example\n",
    "from textblob import TextBlob\n",
    "\n",
    "text=\"This is a very mean and nasty sentence.\"\n",
    "\n",
    "blob = TextBlob(sanitize(text))\n",
    "\n",
    "# result between -1 and +1\n",
    "sentiment_score=blob.sentiment.polarity  # <--\n",
    "\n",
    "print sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive polarity example\n",
    "\n",
    "text=\"This is a nice and positive sentence.\"\n",
    "\n",
    "blob = TextBlob(sanitize(text))\n",
    "\n",
    "# result between -1 and +1\n",
    "sentiment_score=blob.sentiment.polarity  # <--\n",
    "\n",
    "print sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High subjectivity example\n",
    "\n",
    "text=\"This is a very mean and nasty sentence.\"\n",
    "\n",
    "blob = TextBlob(sanitize(text))\n",
    "\n",
    "# result between 0 and +1\n",
    "sentiment_score=blob.sentiment.subjectivity  # <--\n",
    "\n",
    "print sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low subjectivity example\n",
    "\n",
    "text=\"This sentence states a fact.\"\n",
    "\n",
    "blob = TextBlob(sanitize(text))\n",
    "\n",
    "# result between -1 and +1\n",
    "sentiment_score=blob.sentiment.subjectivity  # <--\n",
    "\n",
    "print sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ‚ñ∑ Plotting Sentiment Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's map sentiment ratings across the course of a full book.\n",
    "\n",
    "# First, install matplotlib, numpy, and pandas packages.\n",
    "\n",
    "!pip install --user -U matplotlib numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's relaunch Python so we can access our newly installed modules.\n",
    "\n",
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Viewing available plot styles and selecting one to use.\n",
    "\n",
    "pprint(plt.style.available)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new Moby Dick TextBlob object (just for convenience)\n",
    "\n",
    "import urllib2\n",
    "url=\"http://principalhand.org/workshop-data/Melville_Moby-Dick.txt\"\n",
    "melville_string=urllib2.urlopen(url).read()\n",
    "\n",
    "\n",
    "# Create a TextBlob object and print a random sentence.\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "\n",
    "melville_blob = TextBlob(melville_string)\n",
    "print random.sample(melville_blob.sentences,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melville_sentiments=[sentence.sentiment.polarity for sentence in melville_blob.sentences]\n",
    "print melville_sentiments[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(melville_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing our data before plotting\n",
    "\n",
    "melville_sentiments_pd=pd.Series(melville_sentiments)\n",
    "melville_sentiments_smooth=melville_sentiments_pd.rolling(window=200).mean()\n",
    "\n",
    "print melville_sentiments_smooth[195:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(melville_sentiments_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentiment=max(melville_sentiments_smooth[199:])\n",
    "\n",
    "print max_sentiment # max sentiment polarity value\n",
    "\n",
    "max_sent_index=list(melville_sentiments_smooth).index(max_sentiment) # index position of the 'max_sentiment' value\n",
    "\n",
    "print melville_blob.sentences[max_sent_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sentiment=min(melville_sentiments_smooth[199:])\n",
    "\n",
    "print min_sentiment # min sentiment polarity value\n",
    "\n",
    "min_sent_index=list(melville_sentiments_smooth).index(min_sentiment) # index position of the 'min_sentiment' value\n",
    "\n",
    "print melville_blob.sentences[min_sent_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austen_sentiments=[sentence.sentiment.polarity for sentence in austen_blob.sentences]\n",
    "#print austen_sentiments[:10]\n",
    "austen_sentiments_pd=pd.Series(austen_sentiments)\n",
    "austen_sentiments_smooth=austen_sentiments_pd.rolling(window=200).mean()\n",
    "#print austen_sentiments_smooth[190:210]\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(austen_sentiments_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentiment=max(austen_sentiments_smooth[199:])\n",
    "print max_sentiment # max sentiment polarity value\n",
    "\n",
    "max_sent_index=list(austen_sentiments_smooth).index(max_sentiment) # index position of the 'max_sentiment' value\n",
    "print austen_blob.sentences[max_sent_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sentiment=min(austen_sentiments_smooth[199:])\n",
    "print min_sentiment # min sentiment polarity value\n",
    "\n",
    "min_sent_index=list(austen_sentiments_smooth).index(min_sentiment) # index position of the 'min_sentiment' value\n",
    "print austen_blob.sentences[min_sent_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating functions to expedite the steps we put together above process\n",
    "# These accept an optional second argument for smoothing level. Default is 200 windows.\n",
    "\n",
    "def plot_polarity(text_in,window=200):\n",
    "    blob = TextBlob(sanitize(text_in))\n",
    "    sentiments=[sentence.sentiment.polarity for sentence in blob.sentences]\n",
    "    sentiments_pd=pd.Series(sentiments)\n",
    "    sentiments_smooth=sentiments_pd.rolling(window).mean()\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.plot(sentiments_smooth)\n",
    "\n",
    "def plot_subjectivity(text_in,window=200):\n",
    "    blob = TextBlob(sanitize(text_in))\n",
    "    sentiments=[sentence.sentiment.subjectivity for sentence in blob.sentences]\n",
    "    sentiments_pd=pd.Series(sentiments)\n",
    "    sentiments_smooth=sentiments_pd.rolling(window).mean()\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.plot(sentiments_smooth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persuasion Subjectivity\n",
    "\n",
    "import urllib2\n",
    "url=\"http://principalhand.org/workshop-data/Austen_Persuasion.txt\"\n",
    "temp_string=urllib2.urlopen(url).read()\n",
    "temp_string=temp_string.replace(\"\\r\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \")\n",
    "\n",
    "\n",
    "#plot_polarity(temp_string)\n",
    "plot_subjectivity(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subjectivity(temp_string,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pride and Prejudice Subjectivity\n",
    "\n",
    "import urllib2\n",
    "url=\"http://www.gutenberg.org/cache/epub/1342/pg1342.txt\"\n",
    "temp_string=urllib2.urlopen(url).read()\n",
    "temp_string=temp_string.replace(\"\\r\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \")\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "#plot_polarity(temp_string)\n",
    "plot_subjectivity(temp_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emma Subjectivity\n",
    "\n",
    "import urllib2\n",
    "url=\"http://www.gutenberg.org/cache/epub/158/pg158.txt\"\n",
    "temp_string=urllib2.urlopen(url).read()\n",
    "temp_string=temp_string.replace(\"\\r\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \")\n",
    "\n",
    "\n",
    "#plot_polarity(temp_string)\n",
    "plot_subjectivity(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sense and Sensibility Subjectivity\n",
    "\n",
    "import urllib2\n",
    "url=\"http://www.gutenberg.org/cache/epub/161/pg161.txt\"\n",
    "temp_string=urllib2.urlopen(url).read()\n",
    "temp_string=temp_string.replace(\"\\r\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \")\n",
    "\n",
    "\n",
    "#plot_polarity(temp_string)\n",
    "plot_subjectivity(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjectivity: New York Times Current History; The European War, Vol 2, No. 3, June, 1915\n",
    "\n",
    "import urllib2\n",
    "url=\"http://www.gutenberg.org/cache/epub/15480/pg15480.txt\"\n",
    "temp_string=urllib2.urlopen(url).read()\n",
    "temp_string=temp_string.replace(\"\\r\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \")\n",
    "\n",
    "#plot_polarity(temp_string)\n",
    "plot_subjectivity(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huckleberry Finn Polarity\n",
    "\n",
    "import urllib2\n",
    "url=\"https://www.gutenberg.org/files/76/76-0.txt\"\n",
    "temp_string=urllib2.urlopen(url).read()\n",
    "temp_string=temp_string.replace(\"\\r\",\" \").replace(\"\\n\",\" \").replace(\"  \",\" \")\n",
    "\n",
    "\n",
    "plot_polarity(temp_string)\n",
    "#plot_subjectivity(temp_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ñ∑ Plotting smoothed random data (for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting completely random data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_vals=np.random.rand(4000)\n",
    "\n",
    "vals_pd=pd.Series(random_vals)\n",
    "vals_smooth=vals_pd.rolling(window=200).mean()\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(vals_smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ñ∑ Sentiment Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hist_polarity(text_in):\n",
    "    blob = TextBlob(sanitize(text_in))\n",
    "    sentiments=[sentence.sentiment.polarity for sentence in blob.sentences]\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.hist(sentiments_smooth)\n",
    "\n",
    "def hist_subjectivity(text_in):\n",
    "    blob = TextBlob(sanitize(text_in))\n",
    "    sentiments=[sentence.sentiment.subjectivity for sentence in blob.sentences]\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.hist(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "url=\"http://principalhand.org/workshop-data/Austen_Persuasion.txt\"\n",
    "temp_string=urllib2.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_subjectivity(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These functions remove zero values before plotting.\n",
    "\n",
    "def hist_polarity_filtered(text_in):\n",
    "    blob = TextBlob(text_in.decode(\"utf8\"))\n",
    "    sentiments=[sentence.sentiment.polarity for sentence in blob.sentences]\n",
    "    sentiments=[x for x in sentiments if x != 0]\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.hist(sentiments)\n",
    "\n",
    "def hist_subjectivity_filtered(text_in):\n",
    "    blob = TextBlob(text_in.decode(\"utf8\"))\n",
    "    sentiments=[sentence.sentiment.subjectivity for sentence in blob.sentences]\n",
    "    sentiments=[x for x in sentiments if x != 0]\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.hist(sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_polarity_filtered(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "url=\"http://principalhand.org/workshop-data/Melville_Moby-Dick.txt\"\n",
    "melville_string=urllib2.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_polarity_filtered(melville_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ñ∑ Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=melville_blob\n",
    "melville_sentiments=[sentence.sentiment.subjectivity for sentence in blob.sentences]\n",
    "np.mean(melville_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=austen_blob\n",
    "austen_sentiments=[sentence.sentiment.subjectivity for sentence in blob.sentences]\n",
    "np.mean(austen_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=gilman_blob\n",
    "gilman_sentiments=[sentence.sentiment.subjectivity for sentence in blob.sentences]\n",
    "np.mean(gilman_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ñ∑ Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test of independent values\n",
    "\n",
    "# Inappropriate in this case because zeroes in data make distribution non-normal.\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "print stats.ttest_ind(melville_sentiments,austen_sentiments)\n",
    "\n",
    "print stats.ttest_ind(melville_sentiments,gilman_sentiments)\n",
    "\n",
    "print stats.ttest_ind(austen_sentiments,gilman_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann-Whitney U test\n",
    "\n",
    "# Designed to work for non-normally distrbuted data.\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "print stats.mannwhitneyu(melville_sentiments,austen_sentiments)\n",
    "\n",
    "print stats.mannwhitneyu(melville_sentiments,gilman_sentiments)\n",
    "\n",
    "print stats.mannwhitneyu(austen_sentiments,gilman_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a rel=\"license\"\n",
    "     href=\"http://creativecommons.org/publicdomain/zero/1.0/\">\n",
    "    <img src=\"http://i.creativecommons.org/p/zero/1.0/88x31.png\" style=\"border-style: none;\" alt=\"CC0\" />\n",
    "  </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
